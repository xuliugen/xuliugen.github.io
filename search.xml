<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[带你发现新大陆！什么是图数据库以及简单入门！]]></title>
    <url>%2FNeo4j%2F2018-01-17-What-is-a-graph-database-and-how-to-get-start.html</url>
    <content type="text"><![CDATA[一、关系型数据库的不适性在众多不同的数据模型里，关系数据模型自20世纪80年代就处于统治地位，而且出现了不少巨头，如Oracle、MySQL，它们也被称为：关系数据库管理系统（RDBMS）。然而，随着关系数据库使用范围的不断扩大，也暴露出一些它始终无法解决问题，其中最主要的是数据建模中的一些缺陷和问题，以及在大数据量和多服务器之上进行水平伸缩的限制。同时，互联网发展也产生了一些新的趋势变化：用户、系统和传感器产生的数据量呈指数增长，数据量不断增加，大数据的存储和处理；新时代互联网形势下的问题急迫性，这一问题因互联网+、社交网络，智能推荐等的大规模兴起和繁荣而变得越加紧迫。而在应对这些趋势时，关系数据库产生了更多的不适应性，从而导致大量解决这些问题中某些特定方面的不同技术出现，它们可以与现有RDBMS相互配合或代替它们。过去的几年间，出现了大量新型数据库，它们被统称为NoSQL数据库。二、NoSQL数据库的数据模型NoSQL（Not Only SQL，不限于SQL）是一类范围非常广泛的持久化解决方案，它们不遵循关系数据库模型，也不使用SQL作为查询语言。其数据存储可以不需要固定的表格模式，也经常会避免使用SQL的JOIN操作，一般有水平可扩展的特征。简言之，NoSQL数据库可以按照它们的数据模型分成4类：键-值存储库（Key-Value-stores）;BigTable实现（BigTable-implementations）;文档库（Document-stores）;图形数据库（Graph Database）;在NoSQL四种分类中，图数据库从最近十年的表现来看已经成为关注度最高，也是发展趋势最明显的数据库类型。下图就是db-engines.com对最近三年来所有数据库种类发展趋势的分析结果：看到这里如果以前没有对图数据库有所了解的话可能还是一头雾水，图数据库到底是什么东西！下边我们首先通过一个小案例说一下使用图数据的紧迫性！三、新时期互联网下什么最重要？新时期的互联网下，对于一个公司什么最重要？当然是流量！一个初创公司只要有流量，就可以轻轻松松拿到投资，一个大型互联网只要有流量，就可以轻轻松松躺着赚钱！为了流量企业也是和移动运营商”相互勾结”，推出了诸如：大王卡、大牛卡、宝卡、日租卡、平台应用免流卡等等，各种各样的手机SIM卡，唯一的目的不过就是圈人头！为了圈人头各大公司也是绞尽脑汁，按照增长黑客的指导思想，病毒式的营销方案！利用各种高深算法像你推荐各种东西，例如：脉脉，职场中会向你推荐同一所高校毕业的同事，同一个家乡的同事等等，这些都属于二度人脉的推广！如果把你的微信好友作为一度人脉的话，那么你微信好友的好友就属于你的二度人脉，而你微信好友的好友的好友就是你的三度人脉，画个图简单看一下（图A）：通常情况下我们所指的二度人脉基本都是一个泛指，泛指除了一度人脉之外的所有关联的人脉关系，如：三度、四度、五度甚至六度人脉等！那么问题来了，如果让你实现推荐二度人脉这个功能，你会如何实现哪？四、二度人脉推荐实现及对比相信有一定基础的小伙伴都可以很轻松的实现一个推荐二度人脉的数据库表设计和代码实现。数据库首先有一个用户表user，用于表示用户的基本信息，然后一个有一个好友表user_friends，用于表示好友之间的关系。查找你的一度人脉就是直接根据你的用户ID到user_friends表中查找好友的ID；查找你的二度人脉是先根据你的用户ID去user_friends表中先查出来你的一度人脉，然后得到所有一度人脉的用户ID，然后根据这些所有一度人脉的用户ID再去user_friends中查找他的好友！那么如果让你查找三度、四度、五度人脉哪？哇！想都不敢想！一个复杂的人脉关系网例如图B：如果你确实厉害，对于上述查找三度、四度、五度人脉都是小意思！那么帮忙查一个五度范围内和我是同一个家乡的好友！注意：这里加了一个附加属性“同一个家乡”！可能此时你还认为这是一件简单的事，也不过是先把所有的五度范围内的人脉找出来，然后在搜索一下和我是同一个家乡的而已！厉害了！可能此时你的代码已经完成，然后准备测试！但是，此时的结果可能会让你失望！查询的效率可能会极低极低！完全是一个无法接受的范围！（后边会有测试看结果！）有想法的小伙伴可能已经注意了，利用自己所学的知识，图B不就是一张我们数据结构中的有向图吗？而搜索二度人脉、三度人脉等不就相当于图的一个节点到达另一个节点的路径为2、为3的搜索吗？而图的搜索常用的算法不就是深度优先算法、广度优先算法、迪克拉斯算法吗？看到这里，感觉到你已经领略到图数据库的精髓了！图数据库可以很轻松的实现上述二度人脉、三度人脉等的查询。有一个很有意思的测试，一种是通过关系型数据实现上述功能，一种是通过图数据库实现上述功能，测试的案例是：我们希望在一个社交网络里找到最大深度为5的朋友的朋友。假设随机选择两个人，是否存在一条路径，使得关联他们的关系长度最多为5？对于一个包含100万人，每人约有50个朋友的社交网络， 图数据库与关系型数据库执行时间对比：在深度为2时（即朋友的朋友），假设在一个在线系统中使用，无论关系型数据库还是图数据库，在执行时间方面都表现得足够好。虽然Neo4j的查询时间为关系数据库的2/3，但终端用户很难注意到两者间毫秒级的时间差异。当深度为3时（即朋友的朋友的朋友），很明显关系型数据库无法在合理的时间内实现查询：一个在线系统无法接受30s的查询时间。相比之下，Neo4j的响应时间则保持相对平坦：执行查询仅需要不到1s，这对在线系统来说足够快了。在深度为4时，关系型数据库表现出很严重的延迟，使其无法应用于在线系统。Neo4j所花时间也有所增加，但其时延在在线系统的可接受范围内。最后，在深度为5时，关系型数据库所花时间过长以至于没有完成查询。相比之下，Neo4j则在2 s左右的时间就返回了结果。在深度为5时，事实证明几乎整个网络都是我们的朋友，因此在很多实际用例中，我们可能需要修剪结果，并进行时间控制。将社交网络替换为任何其他领域时，你会发现图数据库在性能、建模和维护方面都能获得类似的好处。无论是音乐还是数据中心管理，无论是生物信息还是足球统计，无论是网络传感器还是时序交易，图都能对这些数据提供强有力而深入的理解。而关系型数据库对于超出合理规模的集合操作普遍表现得不太好。当我们试图从图中挖掘路径信息时，操作慢了下来。我们并非想要贬低关系型数据库，它在所擅长的方面有很好的技术能力，但在管理关联数据时却无能为力。任何超出寻找直接朋友或是寻找朋友的朋友这样的浅遍历查询，都将因为涉及的索引数量而使查找变得缓慢。而图数据库由于使用的是图遍历技术，所需要计算的数据量远小于关系型数据库，所以非常迅速。此时，我们还没有真正的了解到底什么是图数据库，但是我们已经可以领略到图数据库的威力了！五、揭开图数据库的面纱图数据库源起欧拉和图理论，也可称为面向/基于图的数据库，对应的英文是Graph Database。图数据库的基本含义是以“图”这种数据结构存储和查询数据，而不是存储图片的数据库。它的数据模型主要是以节点和关系（边）来体现，也可处理键值对。它的优点是快速解决复杂的关系问题。图具有如下特征：包含节点和边；节点上有属性（键值对）；边有名字和方向，并总是有一个开始节点和一个结束节点；边也可以有属性。说得正式一些，图可以说是顶点和边的集合，或者说更简单一点儿，图就是一些节点和关联这些节点的联系（relationship）的集合。通常，在图计算中，基本的数据结构表达就是：123G=(V, E) V=vertex（节点） E=edge（边）如下图所示：图数据库名字的由来其实与其在底层的存储方式有关，Neo4j底层会以图的方式把用户定义的节点以及关系存储起来，通过这种方式，可以高效的实现从某个节点开始，通过节点与节点间关系，找出两个节点间的联系。从这段描述中可以猜得到，在Neo4j中最重要的两个元素就是节点和关系。说到节点和关系，就必须引出一个非常重要的概念，属性图模型(Property Graph Model)。如下所示:一个图中会记录节点和关系；关系可以用来关联两个节点 ；节点和关系都可以拥有自己的属性；可以赋予节点多个标签(类别)；六、图数据库的代表Neo4j目前市面上有很多图数据库，例如：Neo4J、ArangoDB、OrientDB、FlockDB、GraphDB、InfiniteGraph、Titan、Cayley等，但目前较为活跃可以称之为代表的当属Neo4j。Neo4j官方地址：https://neo4j.com/Neo4j的安装使用很简单，如果是Window平台的话直接安装就可以，然后配置一下环境变量即可使用！这里不再介绍，下边看一下简单使用。1，Neo4j浏览器：Neo4j服务器具有一个集成的浏览器，在一个运行的服务器实例上访问 “http://localhost:7474/”，打开浏览器，显示启动页面：默认的host是bolt://localhost:7687，默认的用户是neo4j，其默认的密码是：neo4j，第一次成功登陆到Neo4j服务器之后，需要重置密码。访问Graph Database需要输入身份验证，Host是Bolt协议标识的主机。2，在Neo4j浏览器中创建节点和关系：示例，编写Cypher命令，创建两个节点和两个关系：1234CREATE (n:Person &#123; name: &apos;Andres&apos;, title: &apos;Developer&apos; &#125;) return n;CREATE (n:Person &#123; name: &apos;Vic&apos;, title: &apos;Developer&apos; &#125;) return n;match(n:Person&#123;name:&quot;Vic&quot;&#125;),(m:Person&#123;name:&quot;Andres&quot;&#125;) create (n)-[r:Friend]-&gt;(m) return r;match(n:Person&#123;name:&quot;Vic&quot;&#125;),(m:Person&#123;name:&quot;Andres&quot;&#125;) create (n)&lt;-[r:Friend]-(m) return r;在$ 命令行中，编写Cypher脚本代码，点击Play按钮，点击创建第一个节点：3、在第一个节点创建之后，在Graph模式下，能够看到创建的图形，继续编写Cypher脚本，创建其他节点和关系：4、在创建完两个节点和关系之后，查看数据库中的图形：七、总结图数据库它善于处理大量的、复杂的、互联的、多变的网状数据，其效率远远高于传统的关系型数据库的百倍、千倍甚至万倍。图数据库特别适用于社交网络、实时推荐、银行交易环路、金融征信系统等广泛的领域。领英、沃尔玛、CISCO、HP、eBay等全球知名企业都在使用图数据库Neo4j，中国企业也在逐步开始用图数据库来构建自己的应用。上文从查找二度人脉的角度一步步引出了图形数据库，并简单的介绍了其概念。本文的主要目的还是以介绍为主，带你认识新技术，而更多的使用以及各种图形数据库之间的对比，优点缺点，仅仅靠一篇文章是完全不够的！还望读者下来之后观望阅读或者自行查找资料进行学习！如果你还没有接触过或者用到图数据库，相信我不久的将来你肯定会接触到或者用到！趁着图形数据库现在还不像MySql或者Redis那样普遍，抓住机会！赶紧好好学习一下吧！参考文章：1、http://www.iteye.com/news/321862、https://www.jianshu.com/p/97c6752e928b3、https://www.cnblogs.com/ljhdo/archive/2017/05/19/5521577.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁简单入门以及三种实现方式介绍]]></title>
    <url>%2FDistributed%2F2018-01-11-Distributed-lock-introduction.html</url>
    <content type="text"><![CDATA[很多小伙伴在学习Java的时候，总是感觉Java多线程在实际的业务中很少使用，以至于不会花太多的时间去学习，技术债不断累积！等到了一定程度的时候对于与Java多线程相关的东西就很难理解，今天需要探讨的东西也是一样的和Java多线程相关的！做好准备，马上开车！学过Java多线程的应该都知道什么是锁，没学过的也不用担心，Java中的锁可以简单的理解为多线程情况下访问临界资源的一种线程同步机制。在学习或者使用Java的过程中进程会遇到各种各样的锁的概念：公平锁、非公平锁、自旋锁、可重入锁、偏向锁、轻量级锁、重量级锁、读写锁、互斥锁等。蒙了吗？不要紧！即使你这些都不会也不要紧，因为这个和今天要探讨的关系不大，不过如果你作为一个爱学习的小伙伴，这里也给你准备了一份秘籍：《Java多线程核心技术》，一共19篇祝你一臂之力！免费版的不过瘾，当然也有收费版的！一、为什么要使用分布式锁我们在开发应用的时候，如果需要对某一个共享变量进行多线程同步访问的时候，可以使用我们学到的Java多线程的18般武艺进行处理，并且可以完美的运行，毫无Bug！注意这是单机应用，也就是所有的请求都会分配到当前服务器的JVM内部，然后映射为操作系统的线程进行处理！而这个共享变量只是在这个JVM内部的一块内存空间！后来业务发展，需要做集群，一个应用需要部署到几台机器上然后做负载均衡，大致如下图：上图可以看到，变量A存在JVM1、JVM2、JVM3三个JVM内存中（这个变量A主要体现是在一个类中的一个成员变量，是一个有状态的对象，例如：UserController控制器中的一个整形类型的成员变量），如果不加任何控制的话，变量A同时都会在JVM分配一块内存，三个请求发过来同时对这个变量操作，显然结果是不对的！即使不是同时发过来，三个请求分别操作三个不同JVM内存区域的数据，变量A之间不存在共享，也不具有可见性，处理的结果也是不对的！如果我们业务中确实存在这个场景的话，我们就需要一种方法解决这个问题！为了保证一个方法或属性在高并发情况下的同一时间只能被同一个线程执行，在传统单体应用单机部署的情况下，可以使用Java并发处理相关的API(如ReentrantLock或Synchronized)进行互斥控制。在单机环境中，Java中提供了很多并发处理相关的API。但是，随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！二、分布式锁应该具备哪些条件在分析分布式锁的三种实现方式之前，先了解一下分布式锁应该具备哪些条件：1、在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；2、高可用的获取锁与释放锁；3、高性能的获取锁与释放锁；4、具备可重入特性；5、具备锁失效机制，防止死锁；6、具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。三、分布式锁的三种实现方式目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。在很多场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。基于数据库实现分布式锁；基于缓存（Redis等）实现分布式锁；基于Zookeeper实现分布式锁；尽管有这三种方案，但是不同的业务也要根据自己的情况进行选型，他们之间没有最好只有更适合！四、基于数据库的实现方式基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。（1）创建一个表：123456789DROP TABLE IF EXISTS `method_lock`;CREATE TABLE `method_lock` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL COMMENT '锁定的方法名', `desc` varchar(255) NOT NULL COMMENT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';（2）想要执行某个方法，就使用这个方法名向表中插入数据：1INSERT INTO method_lock (method_name, desc) VALUES ('methodName', '测试的methodName');因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。（3）成功插入则获取锁，执行完成后删除对应的行数据释放锁：1delete from method_lock where method_name ='methodName';注意：这只是使用基于数据库的一种方法，使用数据库实现分布式锁还有很多其他的玩法！使用基于数据库的这种实现方式很简单，但是对于分布式锁应该具备的条件来说，它有一些问题需要解决及优化：1、因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主备切换；2、不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁；3、没有锁失效机制，因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据；4、不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。5、在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。五、基于Redis的实现方式1、选用Redis实现分布式锁原因：（1）Redis有很高的性能；（2）Redis命令对此支持较好，实现起来比较方便2、使用命令介绍：（1）SETNX1SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。（2）expire1expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。（3）delete1delete key：删除key在使用Redis实现分布式锁的时候，主要就会使用到这三个命令。3、实现思想：（1）获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。（2）获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。（3）释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。4、 分布式锁的简单实现代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * 分布式锁的简单实现代码 * Created by liuyang on 2017/4/20. */public class DistributedLock &#123; private final JedisPool jedisPool; public DistributedLock(JedisPool jedisPool) &#123; this.jedisPool = jedisPool; &#125; /** * 加锁 * @param lockName 锁的key * @param acquireTimeout 获取超时时间 * @param timeout 锁的超时时间 * @return 锁标识 */ public String lockWithTimeout(String lockName, long acquireTimeout, long timeout) &#123; Jedis conn = null; String retIdentifier = null; try &#123; // 获取连接 conn = jedisPool.getResource(); // 随机生成一个value String identifier = UUID.randomUUID().toString(); // 锁名，即key值 String lockKey = "lock:" + lockName; // 超时时间，上锁后超过此时间则自动释放锁 int lockExpire = (int) (timeout / 1000); // 获取锁的超时时间，超过这个时间则放弃获取锁 long end = System.currentTimeMillis() + acquireTimeout; while (System.currentTimeMillis() &lt; end) &#123; if (conn.setnx(lockKey, identifier) == 1) &#123; conn.expire(lockKey, lockExpire); // 返回value值，用于释放锁时间确认 retIdentifier = identifier; return retIdentifier; &#125; // 返回-1代表key没有设置超时时间，为key设置一个超时时间 if (conn.ttl(lockKey) == -1) &#123; conn.expire(lockKey, lockExpire); &#125; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; catch (JedisException e) &#123; e.printStackTrace(); &#125; finally &#123; if (conn != null) &#123; conn.close(); &#125; &#125; return retIdentifier; &#125; /** * 释放锁 * @param lockName 锁的key * @param identifier 释放锁的标识 * @return */ public boolean releaseLock(String lockName, String identifier) &#123; Jedis conn = null; String lockKey = "lock:" + lockName; boolean retFlag = false; try &#123; conn = jedisPool.getResource(); while (true) &#123; // 监视lock，准备开始事务 conn.watch(lockKey); // 通过前面返回的value值判断是不是该锁，若是该锁，则删除，释放锁 if (identifier.equals(conn.get(lockKey))) &#123; Transaction transaction = conn.multi(); transaction.del(lockKey); List&lt;Object&gt; results = transaction.exec(); if (results == null) &#123; continue; &#125; retFlag = true; &#125; conn.unwatch(); break; &#125; &#125; catch (JedisException e) &#123; e.printStackTrace(); &#125; finally &#123; if (conn != null) &#123; conn.close(); &#125; &#125; return retFlag; &#125;&#125;5、测试刚才实现的分布式锁例子中使用50个线程模拟秒杀一个商品，使用–运算符来实现商品减少，从结果有序性就可以看出是否为加锁状态。模拟秒杀服务，在其中配置了jedis线程池，在初始化的时候传给分布式锁，供其使用。1234567891011121314151617181920212223242526272829303132/** * Created by liuyang on 2017/4/20. */public class Service &#123; private static JedisPool pool = null; private DistributedLock lock = new DistributedLock(pool); int n = 500; static &#123; JedisPoolConfig config = new JedisPoolConfig(); // 设置最大连接数 config.setMaxTotal(200); // 设置最大空闲数 config.setMaxIdle(8); // 设置最大等待时间 config.setMaxWaitMillis(1000 * 100); // 在borrow一个jedis实例时，是否需要验证，若为true，则所有jedis实例均是可用的 config.setTestOnBorrow(true); pool = new JedisPool(config, "127.0.0.1", 6379, 3000); &#125; public void seckill() &#123; // 返回锁的value值，供释放锁时候进行判断 String identifier = lock.lockWithTimeout("resource", 5000, 1000); System.out.println(Thread.currentThread().getName() + "获得了锁"); System.out.println(--n); lock.releaseLock("resource", identifier); &#125;&#125;模拟线程进行秒杀服务：12345678910111213141516171819202122public class ThreadA extends Thread &#123; private Service service; public ThreadA(Service service) &#123; this.service = service; &#125; @Override public void run() &#123; service.seckill(); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Service service = new Service(); for (int i = 0; i &lt; 50; i++) &#123; ThreadA threadA = new ThreadA(service); threadA.start(); &#125; &#125;&#125;结果如下，结果为有序的：若注释掉使用锁的部分：1234567public void seckill() &#123; // 返回锁的value值，供释放锁时候进行判断 //String indentifier = lock.lockWithTimeout("resource", 5000, 1000); System.out.println(Thread.currentThread().getName() + "获得了锁"); System.out.println(--n); //lock.releaseLock("resource", indentifier);&#125;从结果可以看出，有一些是异步进行的：5、基于ZooKeeper的实现方式ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于ZooKeeper实现分布式锁的步骤如下：（1）创建一个目录mylock；（2）线程A想获取锁就在mylock目录下创建临时顺序节点；（3）获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；（4）线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；（5）线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。这里推荐一个Apache的开源库Curator，它是一个ZooKeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire方法用于获取锁，release方法用于释放锁。优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式。6、总结上面的三种实现方式，没有在所有场合都是完美的，所以，应根据不同的应用场景选择最适合的实现方式。在分布式环境中，对资源进行上锁有时候是很重要的，比如抢购某一资源，这时候使用分布式锁就可以很好地控制资源。当然，在具体使用中，还需要考虑很多因素，比如超时时间的选取，获取锁时间的选取对并发量都有很大的影响，上述实现的分布式锁也只是一种简单的实现，主要是一种思想，以上包括文中的代码可能并不适用于正式的生产环境，只做入门参考！参考文章：1、https://yq.aliyun.com/articles/606632、http://www.hollischuang.com/archives/17163、https://www.cnblogs.com/liuyang0/p/6744076.html]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试必备技能：JDK动态代理给Spring事务埋下的坑！]]></title>
    <url>%2FSpring%2F2018-01-10-Spring-transaction-and-dynamic-proxy.html</url>
    <content type="text"><![CDATA[一、场景分析最近做项目遇到了一个很奇怪的问题，大致的业务场景是这样的：我们首先设定两个事务，事务parent和事务child，在Controller里边同时调用这两个方法，示例代码如下：1、场景A：1234567891011121314@RestController@RequestMapping(value = "/test")public class OrderController &#123; @Autowired private TestService userService; @GetMapping public void test() &#123; //同时调用parent和child userService.parent(); userService.child(); &#125;&#125;1234567891011121314151617181920@Servicepublic class TestServiceImpl implements TestService &#123; @Autowired private UserMapper userMapper; @Override @Transactional public void parent() &#123; User parent = new User("张大壮 Parent", "123456", 45); userMapper.insert(parent); &#125; @Override @Transactional public void child() &#123; User child = new User("张大壮 Child", "654321", 25); userMapper.insert(child); &#125;&#125;这里其实是分别执行了两个事物，执行的结果是两个方法都可以插入数据！如下：2、场景B：修改上述代码如下：123456789101112@RestController@RequestMapping(value = "/test")public class OrderController &#123; @Autowired private TestService userService; @GetMapping public void test() &#123; userService.parent(); &#125;&#125;12345678910111213141516171819202122@Servicepublic class TestServiceImpl implements TestService &#123; @Autowired private UserMapper userMapper; @Override @Transactional public void parent() &#123; User parent = new User("张大壮 Parent", "123456", 45); userMapper.insert(parent); //在parent里边调用child child(); &#125; @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public void child() &#123; User child = new User("张大壮 Child", "654321", 25); userMapper.insert(child); &#125;&#125;Propagation.REQUIRES_NEW的含义表示：如果当前存在事务，则挂起当前事务并且开启一个新事物继续执行，新事物执行完毕之后，然后在缓刑之前挂起的事务，如果当前不存在事务的话，则开启一个新事物。执行的结果是两个方法都可以插入数据！执行结果如下：场景A和场景B都是正常的执行，期间没有发生任何的回滚，假如child（）方法中出现了异常！3、场景C修改child（）的代码如下所示，其他代码和场景B一样：123456789101112131415@Override @Transactional public void parent() &#123; User parent = new User("张大壮 Parent", "123456", 45); userMapper.insert(parent); child(); &#125; @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public void child() &#123; User child= new User("张大壮 Child", "654321", 25); userMapper.insert(child); throw new RuntimeException("child Exception...................."); &#125;执行结果如下，会出现异常，并且数据都没有插入进去：疑问1：场景C中child（）抛出了异常，但是parent（）没有抛出异常，按道理是不是应该parent（）提交成功而child（）回滚？可能有的小伙伴要说了，child（）抛出了异常在parent（）没有进行捕获，造成了parent（）也是抛出了异常了的！所以他们两个都会回滚！4、场景D按照上述小伙伴的疑问这个时候，如果对parent（）方法修改，捕获child（）中抛出的异常，其他代码和场景C一样：12345678910111213141516171819@Override @Transactional public void parent() &#123; User parent = new User("张大壮 Parent", "123456", 45); userMapper.insert(parent); try &#123; child(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public void child() &#123; User child = new User("张大壮 Child", "654321", 25); userMapper.insert(child); throw new RuntimeException("child Exception...................."); &#125;然后再次执行，结果是两个都插入了数据库：看到这里很多小伙伴都可能会问，按照我们的逻辑来想的话child（）中抛出了异常，parent（）没有抛出并且捕获了child（）抛出了异常！执行的结果应该是child（）回滚，parent（）提交成功的啊！疑问2：场景D为什么不是child（）回滚和parent（）提交成功哪？上述的场景C和场景D似乎融为了一题，要么都成功要么都失败！和我们预期的效果一点都不一样！看到这里这就是我们今天要探讨的主题《JDK动态代理给Spring事务埋下的坑！》接下来我们就分析一下Spring事物在该特定场景下不能回滚的深层次原因！二、问题本质所在我们知道Spring事务管理是通过JDK动态代理的方式进行实现的（另一种是使用CGLib动态代理实现的），也正是因为动态代理的特性造成了上述parent（）方法调用child（）方法的时候造成了child（）方法中的事务失效！简单的来说，在场景D中parent（）方法调用child（）方法的时候，child（）方法的事务是不起作用的，此时的child（）方法像一个没有加事务的普通方法，其本质上就相当于下边的代码：场景C本质：场景D本质：正如上述的代码，我们可以很轻松的解释疑问1和疑问2，因为动态代理的特性造成了场景C和场景D的本质如上述代码。在场景C中，child（）抛出异常没有捕获，相当于parent事务中抛出了异常，造成parent（）一起回滚，因为他们本质是同一个方法；在场景D中，child（）抛出异常并进行了捕获，parent事务中没有抛出异常，parent（）和child（）同时在一个事务里边，所以他们都成功了；看到这里，那么动态代理的这个特性到底是什么才会造成Spring事务失效那？三、动态代理的这个特性到底是什么？首先我们看一下一个简单的动态代理实现方式：123456789101112131415161718192021//接口public interface OrderService &#123; void test1(); void test2();&#125;//接口实现类public class OrderServiceImpl implements OrderService &#123; @Override public void test1() &#123; System.out.println("--执行test1--"); &#125; @Override public void test2() &#123; System.out.println("--执行test2--"); &#125;&#125;12345678910111213141516171819202122232425//代理类public class OrderProxy implements InvocationHandler &#123; private static final String METHOD_PREFIX = "test"; private Object target; public OrderProxy(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //我们使用这个标志来识别是否使用代理还是使用方法本体 if (method.getName().startsWith(METHOD_PREFIX)) &#123; System.out.println("========分隔符========"); &#125; return method.invoke(target, args); &#125; public Object getProxy() &#123; return Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), target.getClass().getInterfaces(), this); &#125;&#125;1234567891011//测试方法public class ProxyDemo &#123; public static void main(String[] args) &#123; OrderService orderService = new OrderServiceImpl(); OrderProxy proxy = new OrderProxy(orderService); orderService = (OrderService) proxy.getProxy(); orderService.test1(); orderService.test2(); &#125;&#125;此时我们执行以下测试方法，注意了此时是同时调用了test1()和test2(）的，执行结果如下：可以看出，在OrderServiceImpl 类中由于test1(）没有调用test2（），他们方法的执行都是使用了代理的，也就是说test1和test2都是通过代理对象调用的invoke（）方法，这和我们场景A和B类似。加入我们模拟一下场景C和场景D在test1(）中调用test2（），那么代码修改为如下：执行结果如下：这里可以很清楚的看出来test1(）走的是代理，而test2（）走的是普通的方法，没有经过代理！看到这里你是否已经恍然大明白了呢？这个应该可以很好的理解为什么是这样子！这是因为在Java中test1（）中调用test2（）中的方法，本质上就相当于把test2（）的方法体放入到test1（）中，也就是内部方法，同样的不管你嵌套了多少层，只有代理对象proxy 直接调用的那一个方法才是真正的走代理的，如下：测试方法和上边的测试方法一样，执行结果如下：记住：只有代理对象proxy直接调用的那个方法才是真正的走代理的！四、如何解决这个坑？上文的分析中我们已经了解了为什么在该特定场景下使用Spring事务的时候造成事务无法回滚的问题，下边我们谈一下几种解决的方法：1、我们可以选择逃避这个问题！我们可以不使用以上这种事务嵌套的方式来解决问题，最简单的方法就是把问题提到Service或者是更靠前的逻辑中去解决，使用service.xxxtransaction是不会出现这种问题的。2、通过AopProxy上下文获取代理对象：（1）SpringBoot配置方式：注解开启 exposeProxy = true，暴露代理对象 (否则AopContext.currentProxy()) 会抛出异常。添加依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;添加注解：修改原有代码的执行方式为：此时的执行结果为：可见，child方法由于异常已经回滚了，而parent可以正确的提交，这才是我们想要的结果！注意的是在parent调用child的时候是通过try/catch捕获了异常的！（2）传统Spring XML配置文件只需要添加依赖个设置如下配置即可，使用方式一样：1&lt;aop:aspectj-autoproxy expose-proxy="true"/&gt;3、通过ApplicationContext上下文进行解决：12345678910111213141516171819202122232425262728293031323334353637383940@Servicepublic class TestServiceImpl implements TestService &#123; @Autowired private UserMapper userMapper; /** * Spring应用上下文 */ @Autowired private ApplicationContext context; private TestService proxy; @PostConstruct public void init() &#123; //从Spring上下文中获取AOP代理对象 proxy = context.getBean(TestService.class); &#125; @Override @Transactional public void parent() &#123; User parent = new User("张大壮 Parent", "123456", 45); userMapper.insert(parent); try &#123; proxy.child(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public void child() &#123; User child = new User("张大壮 Child", "654321", 25); userMapper.insert(child); throw new RuntimeException("child Exception...................."); &#125;&#125;执行结果符合我们的预期：五、总结到此为止，我们简单的介绍了一下Spring事务管理中如果业务中有像场景C或者场景D的情况时，如果不清楚JDK动态代理造成Spring事务无法回滚的问题的话就可能是一个开发事故了，说不定是要扣工资的！上文中简述了几种场景的事务使用和造成事务无法回滚的根本问题，当然讲述的还是表面的现象，并没有深入原理去分析，尽管如此，如果你在面试的时候能够对这个问题说一下自己的了解，也是一个加分项！]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四张图带你了解Tomcat系统架构--让面试官颤抖的Tomcat回答系列！]]></title>
    <url>%2FTomcat%2F2018-01-08-Four-pictures-take-you-through-the-Tomcat-system-architecture.html</url>
    <content type="text"><![CDATA[俗话说，站在巨人的肩膀上看世界，一般学习的时候也是先总览一下整体，然后逐个部分个个击破，最后形成思路，了解具体细节，Tomcat的结构很复杂，但是 Tomcat 非常的模块化，找到了 Tomcat最核心的模块，问题才可以游刃而解，了解了Tomcat的整体架构对以后深入了解Tomcat来说至关重要！一、Tomcat顶层架构先上一张Tomcat的顶层结构图（图A），如下：Tomcat中最顶层的容器是Server，代表着整个服务器，从上图中可以看出，一个Server可以包含至少一个Service，用于具体提供服务。Service主要包含两个部分：Connector和Container。从上图中可以看出 Tomcat 的心脏就是这两个组件，他们的作用如下：1、Connector用于处理连接相关的事情，并提供Socket与Request和Response相关的转化;2、Container用于封装和管理Servlet，以及具体处理Request请求；一个Tomcat中只有一个Server，一个Server可以包含多个Service，一个Service只有一个Container，但是可以有多个Connectors，这是因为一个服务可以有多个连接，如同时提供Http和Https链接，也可以提供向相同协议不同端口的连接,示意图如下（Engine、Host、Context下边会说到）：多个 Connector 和一个 Container 就形成了一个 Service，有了 Service 就可以对外提供服务了，但是 Service 还要一个生存的环境，必须要有人能够给她生命、掌握其生死大权，那就非 Server 莫属了！所以整个 Tomcat 的生命周期由 Server 控制。另外，上述的包含关系或者说是父子关系，都可以在tomcat的conf目录下的server.xml配置文件中看出，下图是删除了注释内容之后的一个完整的server.xml配置文件（Tomcat版本为8.0）详细的配置文件文件内容可以到Tomcat官网查看：http://tomcat.apache.org/tomcat-8.0-doc/index.html上边的配置文件，还可以通过下边的一张结构图更清楚的理解：Server标签设置的端口号为8005，shutdown=”SHUTDOWN” ，表示在8005端口监听“SHUTDOWN”命令，如果接收到了就会关闭Tomcat。一个Server有一个Service，当然还可以进行配置，一个Service有多个，Service左边的内容都属于Container的，Service下边是Connector。二、Tomcat顶层架构小结：（1）Tomcat中只有一个Server，一个Server可以有多个Service，一个Service可以有多个Connector和一个Container；（2） Server掌管着整个Tomcat的生死大权；（4）Service 是对外提供服务的；（5）Connector用于接受请求并将请求封装成Request和Response来具体处理；（6）Container用于封装和管理Servlet，以及具体处理request请求；知道了整个Tomcat顶层的分层架构和各个组件之间的关系以及作用，对于绝大多数的开发人员来说Server和Service对我们来说确实很远，而我们开发中绝大部分进行配置的内容是属于Connector和Container的，所以接下来介绍一下Connector和Container。三、Connector和Container的微妙关系由上述内容我们大致可以知道一个请求发送到Tomcat之后，首先经过Service然后会交给我们的Connector，Connector用于接收请求并将接收的请求封装为Request和Response来具体处理，Request和Response封装完之后再交由Container进行处理，Container处理完请求之后再返回给Connector，最后在由Connector通过Socket将处理的结果返回给客户端，这样整个请求的就处理完了！Connector最底层使用的是Socket来进行连接的，Request和Response是按照HTTP协议来封装的，所以Connector同时需要实现TCP/IP协议和HTTP协议！Tomcat既然处理请求，那么肯定需要先接收到这个请求，接收请求这个东西我们首先就需要看一下Connector！四、Connector架构分析Connector用于接受请求并将请求封装成Request和Response，然后交给Container进行处理，Container处理完之后在交给Connector返回给客户端。因此，我们可以把Connector分为四个方面进行理解：（1）Connector如何接受请求的？（2）如何将请求封装成Request和Response的？（3）封装完之后的Request和Response如何交给Container进行处理的？（4）Container处理完之后如何交给Connector并返回给客户端的？首先看一下Connector的结构图（图B），如下所示：Connector就是使用ProtocolHandler来处理请求的，不同的ProtocolHandler代表不同的连接类型，比如：Http11Protocol使用的是普通Socket来连接的，Http11NioProtocol使用的是NioSocket来连接的。其中ProtocolHandler由包含了三个部件：Endpoint、Processor、Adapter。（1）Endpoint用来处理底层Socket的网络连接，Processor用于将Endpoint接收到的Socket封装成Request，Adapter用于将Request交给Container进行具体的处理。（2）Endpoint由于是处理底层的Socket网络连接，因此Endpoint是用来实现TCP/IP协议的，而Processor用来实现HTTP协议的，Adapter将请求适配到Servlet容器进行具体的处理。（3）Endpoint的抽象实现AbstractEndpoint里面定义的Acceptor和AsyncTimeout两个内部类和一个Handler接口。Acceptor用于监听请求，AsyncTimeout用于检查异步Request的超时，Handler用于处理接收到的Socket，在内部调用Processor进行处理。至此，我们应该很轻松的回答（1）（2）（3）的问题了，但是（4）还是不知道，那么我们就来看一下Container是如何进行处理的以及处理完之后是如何将处理完的结果返回给Connector的？五、Container架构分析Container用于封装和管理Servlet，以及具体处理Request请求，在Connector内部包含了4个子容器，结构图如下（图C）：4个子容器的作用分别是：（1）Engine：引擎，用来管理多个站点，一个Service最多只能有一个Engine；（2）Host：代表一个站点，也可以叫虚拟主机，通过配置Host就可以添加站点；（3）Context：代表一个应用程序，对应着平时开发的一套程序，或者一个WEB-INF目录以及下面的web.xml文件；（4）Wrapper：每一Wrapper封装着一个Servlet；下面找一个Tomcat的文件目录对照一下，如下图所示：Context和Host的区别是Context表示一个应用，我们的Tomcat中默认的配置下webapps下的每一个文件夹目录都是一个Context，其中ROOT目录中存放着主应用，其他目录存放着子应用，而整个webapps就是一个Host站点。我们访问应用Context的时候，如果是ROOT下的则直接使用域名就可以访问，例如：www.ledouit.com,如果是Host（webapps）下的其他应用，则可以使用www.ledouit.com/docs进行访问，当然默认指定的根应用（ROOT）是可以进行设定的，只不过Host站点下默认的主营用是ROOT目录下的。看到这里我们知道Container是什么，但是还是不知道Container是如何进行处理的以及处理完之后是如何将处理完的结果返回给Connector的？别急！下边就开始探讨一下Container是如何进行处理的！六、Container如何处理请求的Container处理请求是使用Pipeline-Valve管道来处理的！（Valve是阀门之意）Pipeline-Valve是责任链模式，责任链模式是指在一个请求处理的过程中有很多处理者依次对请求进行处理，每个处理者负责做自己相应的处理，处理完之后将处理后的请求返回，再让下一个处理着继续处理。但是！Pipeline-Valve使用的责任链模式和普通的责任链模式有些不同！区别主要有以下两点：（1）每个Pipeline都有特定的Valve，而且是在管道的最后一个执行，这个Valve叫做BaseValve，BaseValve是不可删除的；（2）在上层容器的管道的BaseValve中会调用下层容器的管道。我们知道Container包含四个子容器，而这四个子容器对应的BaseValve分别在：StandardEngineValve、StandardHostValve、StandardContextValve、StandardWrapperValve。Pipeline的处理流程图如下（图D）：（1）Connector在接收到请求后会首先调用最顶层容器的Pipeline来处理，这里的最顶层容器的Pipeline就是EnginePipeline（Engine的管道）；（2）在Engine的管道中依次会执行EngineValve1、EngineValve2等等，最后会执行StandardEngineValve，在StandardEngineValve中会调用Host管道，然后再依次执行Host的HostValve1、HostValve2等，最后在执行StandardHostValve，然后再依次调用Context的管道和Wrapper的管道，最后执行到StandardWrapperValve。（3）当执行到StandardWrapperValve的时候，会在StandardWrapperValve中创建FilterChain，并调用其doFilter方法来处理请求，这个FilterChain包含着我们配置的与请求相匹配的Filter和Servlet，其doFilter方法会依次调用所有的Filter的doFilter方法和Servlet的service方法，这样请求就得到了处理！（4）当所有的Pipeline-Valve都执行完之后，并且处理完了具体的请求，这个时候就可以将返回的结果交给Connector了，Connector在通过Socket的方式将结果返回给客户端。总结至此，我们已经对Tomcat的整体架构有了大致的了解，从图A、B、C、D可以看出来每一个组件的基本要素和作用。我们在脑海里应该有一个大概的轮廓了！如果你面试的时候，让你简单的聊一下Tomcat，上面的内容你能脱口而出吗？当你能够脱口而出的时候，这位面试官一定会对你刮目相看的！]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐几款非常实用的IDEA插件]]></title>
    <url>%2FShare%2F2018-01-04-Recommended-several-very-useful-IDEA-plugins.html</url>
    <content type="text"><![CDATA[推荐几款让你开发效率倍增的IDEA插件，解决你开发中可望而又不好找的插件。1、Alibaba Java Coding Guidelines经过247天的持续研发，阿里巴巴于10月14日在杭州云栖大会上，正式发布众所期待的《阿里巴巴Java开发规约》扫描插件！该插件由阿里巴巴P3C项目组研发。P3C是世界知名的反潜机，专门对付水下潜水艇，寓意是扫描出所有潜在的代码隐患。为了让开发者更加方便、快速将规范推动并实行起来，阿里巴巴基于手册内容，研发了一套自动化的IDE检测插件（IDEA、Eclipse）。该插件在扫描代码后，将不符合规约的代码按Blocker/Critical/Major三个等级显示在下方，甚至在IDEA上，我们还基于Inspection机制提供了实时检测功能，编写代码的同时也能快速发现问题所在。对于历史代码，部分规则实现了批量一键修复的功能，如此爽心悦目的功能是不是很值得拥有？提升代码质量，提高团队研发效能，插件将会一路同行。2、iBATIS/MyBatis plugin轻松通过快捷键找到MyBatis中对应的Mapper和XML，CTRL+ALT+B3、GsonFormat当面对一大堆JSON数据需要生成实体对象的时候，这个时候GsonFormat就派上了用场，一键生成对应实体对象4、Stack Overflow编码中几乎所有遇到的错误，都可以在Stack Overflow上找到，因此这个插件可称之为贴心助手，只不过默认使用Google搜索，大家注意。5、Background Image Plus给你一个机会让你面向“对象”编程，设置你喜欢的图片，提升你编码逼格！安装后，在设置界面设置背景图片文件夹，里边放图片，并且可以设置定时更新：设置完图片之后，重启一下IDEA,然后，你懂的！6、Lombokhttp://mp.weixin.qq.com/s?__biz=MzI1NDQ3MjQxNA==&amp;mid=2247484740&amp;idx=1&amp;sn=151715b1f67f0fc20df1df15c3008f26&amp;chksm=e9c5fcf5deb275e35494f4be71e5f71b742e5b321b2fc50a3bc7b7bfbfbd6dd6df4fd76a5185&amp;scene=21#wechat_redirect从今天起让我们忘记Java中的get/set方法吧！7、CodeGlance类似SublimeText的Mini Map插件，看下图就知道什么用了：8、其他插件Markdown support、Maven Helper、JRbel如果你有好的推荐，欢迎留言评论，让更多的人知道好用的东西！]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
</search>
